# CART498-GenAIAssignment4

Jungian psychology encompasses many aspects of dream analysis, particularly relating to how dreams reflect pieces of a person’s life. Analyzing and interpreting dreams involves unpacking not only the setting of a dream and the symbols contained within, but also how a user feels in that context. This general idea guided how I formed my developer prompt for the AI: I gave it the singular goal of interpreting a user’s dream by taking into account their emotional state, understanding what each dream element may represent, and finally linking these insights to personal growth. With a relatively high temperature, the AI’s responses vary significantly, yet every interpretation I’ve seen offers valid insight and thoughtful advice. Lowering the temperature might produce more consistent results, but that consistency conflicts with the abstract nature of dreams. No interpretation is inherently right or wrong, and advice cannot guarantee a better life, as the subconscious can be assessed in countless ways.

Although I’m proud of the final result of my web application, the road getting there was rocky. For whatever reason, Visual Studio Code initially wouldn’t properly connect to the local virtual environment, forcing me to take a crash course on Flask, pip, and Python in general. My prior knowledge of Flask and web development helped, but navigating the fickle nature of VSCode was a nightmare. 

After I got the foundation up and running, I programmed both the text and image AI functionality. The text-based model was already mostly implemented, but its responses often rambled on longer than a few sentences. Initially, the programmer in me wanted to fix this issue by counting two or three periods in the response and automatically cutting off the rest of the output. However, this method would often interrupt the AI mid-thought. It took me embarrassingly long to realize that I could simply ask the AI to limit its responses to a certain number of words. Because of this, I learned that AI is much more powerful and flexible than I gave it credit for, and can adapt to many specific situations.

Image generation was more complex, but it mostly mirrored the text generation set-up within the try-catch block. It ended up working great, though the biggest improvement I would make would be to better emphasize the picture on the page. The major hiccups I ran into were ensuring that the image was the correct size for OpenAI and dealing with b64, the latter of which was surprisingly straightforward after researching instructions online. The benefits of doing online research are incredible, especially compared to beating your head against a wall for a while. Learning to research things sooner would be a great help in many of my projects. 

After styling the page with CSS from past web-development experience and adding finishing touches, like keeping the user’s prompt in the text box after submission, the application was complete. Users simply type a description of a dream or thought, provide details for better results, and click submit. After a short loading period, the AI generates interpretations, insights, and images for the user.
